library(dplyr)
library(ggplot2)
library(caret)
library(e1071) # For SVM
library(nnet) # For multinomial logistic regression
library(rpart) # For decision trees
library(randomForest)
library(ROSE) # For SMOTE and Near Miss
library(pROC) # For AUC and ROC
library(naivebayes)
df <- read.csv("C:/Users/susha/OneDrive/Desktop/online_shoppers_intention.csv")
str(df)
sapply(df, function(x) sum(is.na(x)))
ggplot(data=df, aes(x=Revenue)) + geom_bar(fill=c("#FF9999", "#66B3FF")) + labs(title="Revenue Generated")
df$Month <- as.factor(df$Month)
df$VisitorType <- as.factor(df$VisitorType) # factor data types
df$Weekend <- as.integer(df$Weekend)
df$Revenue <- as.integer(df$Revenue)
str(df)
summary(df)
set.seed(530)
trainIndex <- createDataPartition(df$Revenue, p=0.8, list=FALSE)
train <- df[trainIndex,]
test <- df[-trainIndex,]
train.count <- nrow(train)
test.count <- nrow(test)
print(train.count)
print(test.count)
class_counts <- table(train$Revenue)
class_counts
train_smote <- ovun.sample(Revenue ~ ., data=train, method="over")$data
class_counts <- table(train_smote$Revenue)
class_counts
train$Revenue <- as.factor(train$Revenue)
train_smote$Revenue <- as.factor(train_smote$Revenue)
model_nb <- naive_bayes(Revenue ~ ., data=train)
#model_nb <- naive_bayes(Revenue ~ ., data=train_smote)
pred_nb <- predict(model_nb, test)
pred_nb <- factor(pred_nb, levels = levels(factor(df$Revenue)))
test$Revenue <- factor(test$Revenue, levels = levels(factor(df$Revenue)))
confusionMatrix(pred_nb, test$Revenue)
# Logistic Regression
model_lr <- multinom(Revenue ~ ., data=train)
pred_lr <- predict(model_lr, test)
pred_lr <- factor(pred_lr, levels = levels(factor(df$Revenue)))
test$Revenue <- factor(test$Revenue, levels = levels(factor(df$Revenue)))
confusionMatrix(pred_lr, test$Revenue)
library(dplyr)
library(ggplot2)
library(caret)
library(e1071) # For SVM
library(nnet) # For multinomial logistic regression
library(rpart) # For decision trees
library(randomForest)
library(ROSE) # For SMOTE and Near Miss
library(pROC) # For AUC and ROC
library(naivebayes)
df <- read.csv("C:/Users/susha/OneDrive/Desktop/online_shoppers_intention.csv")
library(dplyr)
library(ggplot2)
library(caret)
library(e1071) # For SVM
library(nnet) # For multinomial logistic regression
library(rpart) # For decision trees
library(randomForest)
library(ROSE) # For SMOTE and Near Miss
library(pROC) # For AUC and ROC
library(naivebayes)
df <- read.csv("C:/Users/susha/OneDrive/Desktop/online_shoppers_intention.csv")
str(df)
sapply(df, function(x) sum(is.na(x)))
ggplot(data=df, aes(x=Revenue)) + geom_bar(fill=c("#FF9999", "#66B3FF")) + labs(title="Revenue Generated")
df$Month <- as.factor(df$Month)
df$VisitorType <- as.factor(df$VisitorType) # factor data types
df$Weekend <- as.integer(df$Weekend)
df$Revenue <- as.integer(df$Revenue)
str(df)
summary(df)
set.seed(530)
trainIndex <- createDataPartition(df$Revenue, p=0.8, list=FALSE)
train <- df[trainIndex,]
test <- df[-trainIndex,]
class_counts <- table(train$Revenue)
class_counts
train_smote <- ovun.sample(Revenue ~ ., data=train, method="over")$data
class_counts <- table(train_smote$Revenue)
class_counts
train$Revenue <- as.factor(train$Revenue)
train_smote$Revenue <- as.factor(train_smote$Revenue)
# Naive Bayes
model_nb <- naive_bayes(Revenue ~ ., data=train)
#model_nb <- naive_bayes(Revenue ~ ., data=train_smote)
pred_nb <- predict(model_nb, test)
pred_nb <- factor(pred_nb, levels = levels(factor(df$Revenue)))
test$Revenue <- factor(test$Revenue, levels = levels(factor(df$Revenue)))
confusionMatrix(pred_nb, test$Revenue)
roc_data <- rbind(roc_data, add_roc_curve(pred_nb, as.numeric(as.character(test$Revenue)) - 1, "Naive Bayes"))
add_roc_curve <- function(predictions, actual, model_name) {
roc_obj <- roc(actual, predictions)
df_roc <- data.frame(
tpr = roc_obj$sensitivities,
fpr = roc_obj$specificities,
model = model_name
)
return(df_roc)
}
# Naive Bayes
model_nb <- naive_bayes(Revenue ~ ., data=train)
#model_nb <- naive_bayes(Revenue ~ ., data=train_smote)
pred_nb <- predict(model_nb, test)
pred_nb <- factor(pred_nb, levels = levels(factor(df$Revenue)))
test$Revenue <- factor(test$Revenue, levels = levels(factor(df$Revenue)))
confusionMatrix(pred_nb, test$Revenue)
roc_data <- rbind(roc_data, add_roc_curve(pred_nb, as.numeric(as.character(test$Revenue)) - 1, "Naive Bayes"))
library(dplyr)
library(ggplot2)
library(caret)
library(e1071) # For SVM
library(nnet) # For multinomial logistic regression
library(rpart) # For decision trees
library(randomForest)
library(ROSE) # For SMOTE and Near Miss
library(pROC) # For AUC and ROC
library(naivebayes)
df <- read.csv("C:/Users/susha/OneDrive/Desktop/online_shoppers_intention.csv")
str(df)
sapply(df, function(x) sum(is.na(x)))
ggplot(data=df, aes(x=Revenue)) + geom_bar(fill=c("#FF9999", "#66B3FF")) + labs(title="Revenue Generated")
df$Month <- as.factor(df$Month)
df$VisitorType <- as.factor(df$VisitorType) # factor data types
df$Weekend <- as.integer(df$Weekend)
df$Revenue <- as.integer(df$Revenue)
str(df)
summary(df)
set.seed(530)
trainIndex <- createDataPartition(df$Revenue, p=0.8, list=FALSE)
train <- df[trainIndex,]
test <- df[-trainIndex,]
class_counts <- table(train$Revenue)
class_counts
train_smote <- ovun.sample(Revenue ~ ., data=train, method="over")$data
class_counts <- table(train_smote$Revenue)
class_counts
train$Revenue <- as.factor(train$Revenue)
train_smote$Revenue <- as.factor(train_smote$Revenue)
roc_data <- data.frame(tpr = numeric(), fpr = numeric(), model = character())
# Function to add ROC curve data
add_roc_curve <- function(predictions, actual, model_name) {
roc_obj <- roc(actual, predictions)
df_roc <- data.frame(
tpr = roc_obj$sensitivities,
fpr = roc_obj$specificities,
model = model_name
)
return(df_roc)
}
# Naive Bayes
model_nb <- naive_bayes(Revenue ~ ., data=train)
#model_nb <- naive_bayes(Revenue ~ ., data=train_smote)
pred_nb <- predict(model_nb, test)
pred_nb <- factor(pred_nb, levels = levels(factor(df$Revenue)))
test$Revenue <- factor(test$Revenue, levels = levels(factor(df$Revenue)))
confusionMatrix(pred_nb, test$Revenue)
roc_data <- rbind(roc_data, add_roc_curve(pred_nb, as.numeric(as.character(test$Revenue)) - 1, "Naive Bayes"))
library(dplyr)
library(ggplot2)
library(caret)
library(e1071) # For SVM
library(nnet) # For multinomial logistic regression
library(rpart) # For decision trees
library(randomForest)
library(ROSE) # For SMOTE and Near Miss
library(pROC) # For AUC and ROC
library(naivebayes)
df <- read.csv("C:/Users/susha/OneDrive/Desktop/online_shoppers_intention.csv")
str(df)
sapply(df, function(x) sum(is.na(x)))
ggplot(data=df, aes(x=Revenue)) + geom_bar(fill=c("#FF9999", "#66B3FF")) + labs(title="Revenue Generated")
df$Month <- as.factor(df$Month)
df$VisitorType <- as.factor(df$VisitorType) # factor data types
df$Weekend <- as.integer(df$Weekend)
df$Revenue <- as.integer(df$Revenue)
str(df)
summary(df)
set.seed(530)
trainIndex <- createDataPartition(df$Revenue, p=0.8, list=FALSE)
train <- df[trainIndex,]
test <- df[-trainIndex,]
class_counts <- table(train$Revenue)
class_counts
train_smote <- ovun.sample(Revenue ~ ., data=train, method="over")$data
test$Revenue_numeric <- as.numeric(as.character(test$Revenue)) - 1
class_counts <- table(train_smote$Revenue)
class_counts
train$Revenue <- as.factor(train$Revenue)
train_smote$Revenue <- as.factor(train_smote$Revenue)
roc_data <- data.frame(tpr = numeric(), fpr = numeric(), model = character())
# Function to add ROC curve data
add_roc_curve <- function(predictions, actual, model_name) {
roc_obj <- roc(actual, predictions)
df_roc <- data.frame(
tpr = roc_obj$sensitivities,
fpr = roc_obj$specificities,
model = model_name
)
return(df_roc)
}
# Naive Bayes
model_nb <- naive_bayes(Revenue ~ ., data=train)
#model_nb <- naive_bayes(Revenue ~ ., data=train_smote)
pred_nb <- predict(model_nb, test)
pred_nb <- factor(pred_nb, levels = levels(factor(df$Revenue)))
test$Revenue <- factor(test$Revenue, levels = levels(factor(df$Revenue)))
confusionMatrix(pred_nb, test$Revenue)
roc_data <- rbind(roc_data, add_roc_curve(pred_nb, as.numeric(as.character(test$Revenue)) - 1, "Naive Bayes"))
roc_data <- rbind(roc_data, add_roc_curve(pred_nb, as.numeric(as.character(test$Revenue)) - 1, "Naive Bayes"))
library(dplyr)
library(ggplot2)
library(caret)
library(e1071) # For SVM
library(nnet) # For multinomial logistic regression
library(rpart) # For decision trees
library(randomForest)
library(ROSE) # For SMOTE and Near Miss
library(pROC) # For AUC and ROC
library(naivebayes)
library(dplyr)
library(ggplot2)
library(caret)
library(e1071) # For SVM
library(nnet) # For multinomial logistic regression
library(rpart) # For decision trees
library(randomForest)
library(ROSE) # For SMOTE and Near Miss
library(pROC) # For AUC and ROC
library(naivebayes)
# Read data
df <- read.csv("C:/Users/susha/OneDrive/Desktop/online_shoppers_intention.csv")
df$Month <- as.factor(df$Month)
df$VisitorType <- as.factor(df$VisitorType)
df$Weekend <- as.integer(df$Weekend)
df$Revenue <- as.factor(df$Revenue)
# Split data
set.seed(42)
trainIndex <- createDataPartition(df$Revenue, p=0.75, list=FALSE)
train <- df[trainIndex,]
test <- df[-trainIndex,]
# Convert test$Revenue to numeric for ROC analysis (0 for negative class, 1 for positive class)
test$Revenue_numeric <- as.numeric(test$Revenue) - 1
# Over-sampling using SMOTE
train_smote <- ovun.sample(Revenue ~ ., data=train, method="over")$data
# Initialize an empty dataframe to store ROC data
roc_data <- data.frame(tpr = numeric(), fpr = numeric(), model = character())
# Function to add ROC curve data
add_roc_curve <- function(predictions, actual, model_name) {
roc_obj <- roc(actual, predictions)
df_roc <- data.frame(
tpr = roc_obj$sensitivities,
fpr = roc_obj$specificities,
model = model_name
)
return(df_roc)
}
# Naive Bayes
model_nb <- naive_bayes(Revenue ~ ., data=train_smote)
pred_nb <- predict(model_nb, test, type="raw")[,2]
roc_data <- rbind(roc_data, add_roc_curve(pred_nb, test$Revenue_numeric, "Naive Bayes"))
library(dplyr)
library(ggplot2)
library(caret)
library(e1071) # For SVM
library(nnet) # For multinomial logistic regression
library(rpart) # For decision trees
library(randomForest)
library(ROSE) # For SMOTE and Near Miss
library(pROC) # For AUC and ROC
library(naivebayes)
# Read data
df <- read.csv("C:/Users/susha/OneDrive/Desktop/online_shoppers_intention.csv")
df$Month <- as.factor(df$Month)
df$VisitorType <- as.factor(df$VisitorType)
df$Weekend <- as.integer(df$Weekend)
df$Revenue <- as.factor(df$Revenue)
# Split data
set.seed(42)
trainIndex <- createDataPartition(df$Revenue, p=0.75, list=FALSE)
train <- df[trainIndex,]
test <- df[-trainIndex,]
# Convert test$Revenue to numeric for ROC analysis (0 for negative class, 1 for positive class)
test$Revenue_numeric <- as.numeric(test$Revenue) - 1
# Over-sampling using SMOTE
train_smote <- ovun.sample(Revenue ~ ., data=train, method="over")$data
# Initialize an empty dataframe to store ROC data
roc_data <- data.frame(tpr = numeric(), fpr = numeric(), model = character())
# Function to add ROC curve data
add_roc_curve <- function(predictions, actual, model_name) {
roc_obj <- roc(actual, predictions)
df_roc <- data.frame(
tpr = roc_obj$sensitivities,
fpr = roc_obj$specificities,
model = model_name
)
return(df_roc)
}
# Naive Bayes
model_nb <- naive_bayes(Revenue ~ ., data=train_smote)
pred_nb <- predict(model_nb, test, type="prob")[,2]
roc_data <- rbind(roc_data, add_roc_curve(pred_nb, test$Revenue_numeric, "Naive Bayes"))
# Logistic Regression
model_lr <- multinom(Revenue ~ ., data=train)
pred_lr <- predict(model_lr, test, type="prob")[,2]
pred_lr_full <- predict(model_lr, test, type="prob")
pred_lr <- predict(model_lr, test, type="prob")[,2]
roc_data <- rbind(roc_data, add_roc_curve(pred_lr, test$Revenue_numeric, "Logistic Regression"))
